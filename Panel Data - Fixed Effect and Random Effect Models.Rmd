---
title: "Panel Data - Fixed Effect and Random Effect Models"
author: "Michael Winton"
date: \today
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
header-includes: \usepackage{amsmath}
geometry: margin=1in
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=4, fig.height=3.5, warn=FALSE)

library(car)
library(GGally)
library(plm)
library(Ecdat)  # sample datasets
library(stargazer) # summarize models
library(wooldridge)  # sample datasets
```

## Fixed Effect Transformation

Whereas the First Difference models eliminate the time-invariant unobserved variables by subtracting one observation from another, the Fixed Effect Transformation involves subtracting out the individual's average (over time) from each observation.

If we have observations from $i=1,2,...n$ individuals and $t=1,2,...T$ periods:

$$y_{it} = \beta_0 + \beta_1 x_{it} + a_i + \epsilon_{it}$$
Averaging individuals over time:

$$\bar{y}_i = \beta_0 + \beta_1 \bar{x}_i + \bar{a}_i + \bar{\epsilon}_{it} $$

Subtracting, we get:

$$ y_{it} - \bar{y}_i =  \beta_1 (\bar{x}_i - \bar{x}_i) +  (\epsilon_{it} - \bar{\epsilon}_{it}) $$
Notice that both the intercept $\beta_0$ and the time-invariant unobserved variables $a_i$, also known as the _unobserved individual heterogeneity_ have dropped out.  We refer to $y_{it} - \bar{y}_i$ as the _demeaned_ response variable.

The more general form of the equation with $k$ explanatory variables is:

$$ y_{it} - \bar{y}_i =  \beta_1 (\bar{x}_{i1} - \bar{x}_{i1}) +  \beta_2 (\bar{x}_{i2} - \bar{x}_{i2}) +  ... + \beta_k (\bar{x}_{ik} - \bar{x}_{ik}) +  + (\epsilon_{it} - \bar{\epsilon}_{it}) $$

As with the First Difference transformation, any explanatory variables that are constant in the dataset will be dropped out, too.  Variables with very little variation will become almost constant after transformation.  _Interactions_ with time-invariant variables can be estimated through use of (time) dummy variables.  However, if a full set of time dummies is included, then its impossible to estimate the effect of deterministic time-varying variables because they can't be distinguished from aggregate time effect.

#### Estimating Fixed Effects model with OLS

This time-demeaned equation can then be estimated by OLS.  It uses time variation _within_ each of the cross-sectional units (subjects) in the dataset.  Because of this, the fixed effect transformation is also called _within transformation_. CLM assumptions are still required in order for estimators to be consistent.  $\epsilon_{it}$ must have zero-conditional mean ($E(\epsilon_{it} | X_i, a_i)=0 \  \forall t$), homoskedasticity, and serially uncorrelated across $t$.

The poolability test in `pooltest` has a null hypothesis that the slope coefficient is constant across time.  The serial correlation test in `pbgtest` has a null hypothesis of _no_ serial correlation.  
```{r}
data("Grunfeld")
head(Grunfeld)

# test for poolability
znp <- pvcm(inv ~ value + capital, data=Grunfeld, model='within')
zplm <- plm(inv ~ value + capital, data=Grunfeld)
pooltest(zplm, znp)

# test for serial correlation
grun_panel <- pdata.frame(Grunfeld, index=c('firm','year'))
grun_fe <- plm(inv ~ value + capital, data=grun_panel, model='within')
pbgtest(grun_fe, order=2)
```

In this case, we strongly reject the null hypothesis for poolability and for no serial correlation.


### Between Estimators

We do not focus on the coefficients of the "average" equation above, as they are biased when the observed explanatory variables $x$ are correlated with the unobserved fixed effect $a_i$.  Additionally, these don't use the panel data efficiently, as they lose the time element.

If we think the explanatory variables and the unobserved fixed effect are _uncorrelated_, we would be better off using the **random effect model**.

### Example: job training effect on manufacturing scrap rate

```{r}
data(jtrain)  # from Wooldridge
str(jtrain)
table(jtrain$year)
# head(jtrain,12)
```

We see there are 157 individuals in the panel.  We have indicator variables for `d88` and `d89`.

```{r}
# split the dataframe by year
tmp <- split.data.frame(jtrain, as.factor(jtrain$year))
jtrain_87 <- tmp$'1987'
jtrain_88 <- tmp$'1988'
jtrain_89 <- tmp$'1989'
```
#### OLS Method (1987 only)
```{r}
# let's ignore 1988 and 1989, and estimate a model based on 1987
# employ = number of employees
# hrsemp = number of hours of training per employee
# sales = annual firm sales in $
# scrap = # units scrapped
# "l" columns indicate logs
summary(cbind(jtrain_87$lscrap, jtrain_87$lsales, jtrain_87$hrsemp, jtrain_87$lemploy))
jtrain87_ols <- lm(lscrap ~ hrsemp + lemploy + lsales, data=jtrain_87)
summary(jtrain87_ols)
```

This model doesn't tell us anything about change over time, nor does it remove the time-invariant unobserved variables.  As a result, it's possible to have omitted variable bias.

#### The `plm` function

Now let's look at a proper panel model using `plm`.  The `plm` function supports 4 estimation methods:

  1. pooled OLS (model='pooling')
  2. fixed effects (model='within')
  3. random effects (model='random')
  4. first differences (model='fd')
  5. between (model='between')

It also supports unbalanced panels, two-way effects, and instrumental variables.  For example, if you have a model $y$ is related to $x1$ and $x2$ endogenous variables, $x3$ exogenous variable,and $z1$ and $z2$ external instructions, it could specified as either:

    - y ~ x1 + x2 + x3 | x3 + z1 + z2
    - y ~ x1 + x2 + x3 | x. -x1 -x2 + z1 + z2

The `plm` function expects data in a _person-period_ format (ie. one row per person per time period observation).  The `pdata.frame` call is used to add an index to a data frame.

#### Example: First-Difference Method

```{r}
# specify index as (individuals, periods)
jtrain_panel <- pdata.frame(jtrain, index=c('fcode','year'))
# show a sample to see how index is applied
str(jtrain_panel$scrap)

# first difference model
jtrain_fd <- plm(lscrap ~ hrsemp + lsales + lemploy, data=jtrain_panel, model='fd')
summary(jtrain_fd)
```
#### Example: Fixed Effects Method

```{r}
# fixed effects model
jtrain_fe <- plm(lscrap ~ hrsemp + lsales + lemploy, data=jtrain_panel, model='within')
summary(jtrain_fe)
```

## Random Effects Models

The random effects model includes all of the assumptions of the fixed effects model, but also includes the strong requirement that $a_i$ is independent of _all_ explanatory variables in _all_ time periods.

When we can't meet that strong requirement of independence of $a_i$, we used the fixed effect model as a tool for eliminating omitted variable bias.  If we do meet the requirement that $a_i$ is independent, we can get consistent OLS estimators of the regression coefficients $\hat{\beta_j}$ from a single cross-section of our data; we don't need the whole panel.  The value of the random effects model doesn't come in here.

As we did earlier for pooled OLS, we rewrite the equation in a _composite error_ form:

$$ y_{it} = \beta_0 + \beta_1 x_{1it} + ... + \beta_k x_{kit}+ \mu_{it}$$
where in reality $\mu_{it} = a_i + \epsilon_{it}$, and $i=1...n$ and $t=1...T$.  Because $a_i$ is contained in the composite error term in _each time period_, $\mu_{it}$ is serially correlated.  The value in the random effects is that we can use random effects to overcome this serial correlation.

Since pooled OLS _ignores this serial correlation_, it usually results in invalid standard errors and test statistics, even if $a_i$ is uncorrelated with the explanatory variables  The random effects model uses Generalized Least Squares (rather than OLS).  For GLS to have good properties, we need a "short panel", meaning a large $N$ but a small number of $T$ periods.  The GLS transformation that eliminates serial error correlation is (with $\lambda$ between 0-1):

$$ \lambda = \bigg[ \frac{\sigma_e^2}{\sigma_e^2 + T \sigma_a^2} \bigg]^{1/2}$$

The transformed model becomes (where the overbar indicates time averages) :

$$ y_{it} - \lambda \bar{y}_i = \beta_0 (1 - \lambda) + \beta_1(x_{1it}- \bar{x}_{1i}) + ... + \beta_k (x_{kit}- \bar{x}_{ki}) + (\mu_{it} - \lambda \bar{\mu}_i)$$

So, in words, whereas the fixed effects model subtracts the _entire_ time averages from the corresponding variables, the random effects model subtracts a _fraction_ of those time averages, with that fraction $\lambda$ being a function of $\sigma_e, \sigma_a, T$.  The GLS estimator is simply the pooled estimator of this transformed equation.

In practice, we will not know the actual $\sigma_e, \sigma_a$, so we will need to estimate $\lambda$ based on pooled OLS or fixed effect residuals.  The `plm` package will automatically calculate the random effect estimator $\hat{\lambda}$.  Under random effect assumptions, this estimator $\hat{\lambda}$ will be consistent and asymptotically normally distributed for large $N$ and fixed $T$.

One important benefit of the random effects model (contrasted against the fixed effects model) is that it allows for time-independent explanatory variables.  With the random effects model, they do not get completely subtracted out.

## Example: comparing models with wage data

In reality, when we are estimating either FE or RE models, it's usually informative to also run a pooled OLS model.  Comparing the results of the 3 models can help identify the nature of biases left completely in the composite error term (pooled OLS), or partially so (RE).

Let's do an example with wage data vs. education and race dummies, which drop out of the FE model since they're constant over time, as well as time-varying variables for experience (and also its square), union, and married.

```{r}
data("wagepan")  # this is a short panel (545 individuals, 8 periods)
wage_plm <- pdata.frame(wagepan, index=c('nr', 'year'))
mod_pooled <- plm(lwage ~ educ + black + hisp + exper + exper^2 + married + union, 
                  data=wage_plm, model='pooling')
mod_re <- plm(lwage ~ educ + black + hisp + exper + exper^2 + married + union, 
                  data=wage_plm, model='random')
mod_fe <- plm(lwage ~ educ + black + hisp + exper + exper^2 + married + union, 
                  data=wage_plm, model='within')
stargazer(mod_pooled, mod_re, mod_fe, type="text", omit.stat='f',
          column.labels=c('Pooled','RE','FE'))
```
Observations:

    - Coefficients for education, black, and hispanic are similar for pooled and RE
    - Pooled OLS standard errors underestimate the true errors due to serial correlation
    - Compared to pooled model, marriage and union effects are much smaller in RE model
    - In FE model, (which eliminates unboserved fixed effects), marriage and union effects both drop substantially
    
## Takeaways: Fixed Effects vs. Random Effects

Because FE model allows for arbitrary correlation between $a_i$ and explanatory variables (RE does not), FE is considered a more convincing tool for determining "ceteris paribus" effects.  However, random effects models are particularly important if the explanatory variables are constant over time.  

Also, RE model is generally more _efficient_ (ie. needs fewer observations to achieve a given performance) than the Pooled OLS model. 
    
Just keep in mind that the assumption that $a_i$ is uncorrelated with all explanatory variables over time is often not a reasonable assumption.  When we use it, we should give substantial reasons why we consider it valid.  There is also a **Hausman** test for the full set of RE assumptions.
